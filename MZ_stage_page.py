import streamlit as st
from openai import OpenAI

from funcs.get_system_content import get_system_content
from funcs.get_teaching_prompt import get_teaching_prompt
from funcs.get_test_case import get_test_case
from funcs.config_loader import load_config
from funcs.print_chat_history import print_chat_histroy
from funcs.run_test_case import run_test_case
from funcs.handler_user_input import handler_user_input
from funcs.reset_chat import reset_chat
from funcs.get_base_prompt import get_base_prompt

def MZ_stage_page(stage):      
    st.title(stage)
    config_name_dict = {
        'MZ stage 3. ëª…ë ¹ì–´ Teaching': 'MZ_stage_3_command',
        'MZ stage 3. forë¬¸ Teaching': 'MZ_stage_3_for',
        'MZ stage 4. ì¤‘ì²©ë°˜ë³µë¬¸ Teaching': 'MZ_stage_4_nestedloop',
        'MZ stage 4. while, NotDone() Teaching': 'MZ_stage_4_while_notDone',
        'MZ stage 5. ifë¬¸, ì¡°ê±´ ëª…ë ¹ì–´ Teaching': 'MZ_stage_5',
        'MZ stage 6. elseë¬¸ Teaching': 'MZ_stage_6',
        'MZ stage 7. elifë¬¸, ê°ˆë¦¼ê¸¸ ëª…ë ¹ì–´ Teaching': 'MZ_stage_7'
    }
    config_name = config_name_dict[stage]

    # ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥ ë°›ê¸°
    st.sidebar.header("API ì„¤ì •")
    api_key_input = st.sidebar.text_input("OpenAI API Key", type="password")

    if not api_key_input:
        st.warning("API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    client = OpenAI(api_key=api_key_input)

    gpt_model = 'gpt-4.1-mini'
    st.sidebar.markdown('# gpt model')
    st.sidebar.markdown(gpt_model)

    st.sidebar.markdown("# Prompt")
    config = load_config(config_name)
    
    # system content ë¶ˆëŸ¬ì˜¤ê¸°
    system_content = get_system_content(config['system_content_path'])

    # system content ë³´ê¸° ì˜µì…˜
    show_system_content = st.sidebar.checkbox("System Content ë³´ê¸°", value=False)
    if show_system_content:    
        st.sidebar.markdown("### System Content")
        st.sidebar.text(system_content)

    # teaching prompt ë¶ˆëŸ¬ì˜¤ê¸°
    teaching_prompt = get_teaching_prompt(config['teaching_prompt_path'])

    # teaching prompt ë³´ê¸° ì˜µì…˜
    show_teaching_prompt = st.sidebar.checkbox("Teaching Prompt ë³´ê¸°", value=False)
    if show_teaching_prompt:   
        st.sidebar.markdown("### Teaching Prompt")
        st.sidebar.text(teaching_prompt)
    
    # Test case
    test_case = get_test_case(config['test_case_path'])
    st.sidebar.markdown("# Test Case")
    st.sidebar.text(config['test_case_label'])
    st.sidebar.image(config['test_case_image'])

    # âœ… system messageë¥¼ í¬í•¨í•œ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.input_count = 0
        st.session_state.messages = [
            {"role": "system", "content": system_content}
        ]

    # ëŒ€í™” ë‚´ì—­ ì¶œë ¥
    print_chat_histroy(st.session_state.messages)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("AI Teachingì„ ì§„í–‰í•˜ì„¸ìš”!"):
        st.session_state.input_count += 1

        if st.session_state.input_count == 1:
            front = get_base_prompt(config["first_teaching_base_front"])
            back = get_base_prompt(config["first_teaching_base_back"])

        else :
            front = get_base_prompt(config["second_teaching_base_front"])
            back = get_base_prompt(config["second_teaching_base_back"])

        prompt_with_base = front + prompt + back

        handler_user_input(prompt_with_base, client, gpt_model)

    # Test Case ìë™ì‹¤í–‰
    if st.button("â–¶ï¸ Test Case ì‹¤í–‰ (AIëŠ” ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"):
        print(test_case)
        run_test_case(test_case, client, gpt_model)

    # ğŸ” ëŒ€í™” ë¦¬ì…‹ ë²„íŠ¼ (system ë©”ì‹œì§€ ì œì™¸)
    if st.button("âš ï¸ ëŒ€í™” ë¦¬ì…‹"):
        st.session_state.input_count = 0
        reset_chat()
