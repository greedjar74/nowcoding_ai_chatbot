import streamlit as st
from openai import OpenAI
import io
import contextlib

from funcs.get_system_content import get_system_content
from funcs.get_teaching_prompt import get_teaching_prompt
from funcs.get_test_case import get_test_case
from funcs.config_loader import load_config
from funcs.print_chat_history import print_chat_histroy
from funcs.run_test_case import run_test_case
from funcs.handler_user_input import handler_user_input
from funcs.reset_chat import reset_chat
from funcs.get_base_prompt import get_base_prompt

def NP_stage_1_2_3_5_6_7(stage):
    st.title(stage)
    config_name_dict = {
        'NP stage 1. ë¬¸ì œ, ëª…ë ¹ì–´ Teaching': ['NP_stage_1', 'gpt-4.1-mini'],
        'NP stage 2. ë¹„êµì—°ì‚°ì Teaching': ['NP_stage_2', 'gpt-4.1-mini'],
        'NP stage 3. forë¬¸ ë²”ìœ„ ì„¤ì • Teaching': ['NP_stage_3', 'gpt-4.1-mini'],
        'NP stage 5. ëŒ€ê°ì„  íŒ¨í„´ Teaching': ['NP_stage_5', 'o4-mini'],
        'NP stage 6. ì§ì‚¬ê°í˜• íŒ¨í„´ Teaching': ['NP_stage_6', 'o4-mini'],
        'NP stage 7. x, y ì—°ì‚° íŒ¨í„´ Teaching': ['NP_stage_7', 'o4-mini'],
        'NP stage 8-1. ì¢…í•©(ì„¸ë¡œ ì§ì„  íŒ¨í„´)': ['NP_stage_8_1', 'o4-mini'],
        'NP stage 8-2. ì¢…í•©(ì •ì‚¬ê°í˜• íŒ¨í„´)': ['NP_stage_8_2', 'o4-mini'],
        'NP stage 8-3. ì¢…í•©((x+y)%5==0 íŒ¨í„´)': ['NP_stage_8_3', 'o4-mini']
    }
    config_name = config_name_dict[stage][0]

    # ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ ì…ë ¥ ë°›ê¸°
    st.sidebar.header("API ì„¤ì •")
    api_key_input = st.sidebar.text_input("OpenAI API Key", type="password")

    if not api_key_input:
        st.warning("API í‚¤ë¥¼ ì‚¬ì´ë“œë°”ì— ì…ë ¥í•´ì£¼ì„¸ìš”.")
        return

    client = OpenAI(api_key=api_key_input)

    gpt_model = config_name_dict[stage][1]
    st.sidebar.markdown('# gpt model')
    st.sidebar.markdown(gpt_model)

    st.sidebar.markdown("# Prompt")
    config = load_config(config_name)
    
    # system content ë¶ˆëŸ¬ì˜¤ê¸°
    system_content = get_system_content(config['system_content_path'])

    # system content ë³´ê¸° ì˜µì…˜
    show_system_content = st.sidebar.checkbox("System Content ë³´ê¸°", value=False)
    if show_system_content:    
        st.sidebar.markdown("### System Content")
        st.sidebar.text(system_content)

    # teaching prompt ë¶ˆëŸ¬ì˜¤ê¸°
    teaching_prompt = get_teaching_prompt(config['teaching_prompt_path'])

    # teaching prompt ë³´ê¸° ì˜µì…˜
    show_teaching_prompt = st.sidebar.checkbox("Teaching Prompt ë³´ê¸°", value=False)
    if show_teaching_prompt:   
        st.sidebar.markdown("### Teaching Prompt")
        st.sidebar.text(teaching_prompt)
    
    # Test case
    test_case = get_test_case(config['test_case_path'])
    st.sidebar.markdown("# Test Case")
    st.sidebar.text(config['test_case_label'])
    st.sidebar.image(config['test_case_image'])

    # âœ… system messageë¥¼ í¬í•¨í•œ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "system", "content": system_content}
        ]

    # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
    print_chat_histroy(st.session_state.messages)

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("AI Teachingì„ ì§„í–‰í•˜ì„¸ìš”!"):
        if '<ëª…ë ¹ì–´ ì„¤ëª…>' in prompt:
            back = get_base_prompt(config["first_teaching_base_back"])

        elif '<ë¬¸ì œ ì„¤ëª…>' in prompt:
            back = get_base_prompt(config["second_teaching_base_back"])

        elif '<ë²”ìœ„ì„¤ì • ì„¤ëª…>' in prompt:
            back = get_base_prompt(config["third_teaching_base_back"])

        elif '<ì œì•½ì¡°ê±´ ì„¤ëª…>' in prompt:
            back = get_base_prompt(config["fourth_teaching_base_back"])

        elif '<íŒ¨í„´ ì„¤ëª…>' in prompt:
            back = get_base_prompt(config["fifth_teaching_base_back"])

        else :
            back = get_base_prompt(config["sixth_teaching_base_back"])

        prompt_with_base = prompt + back

        handler_user_input(prompt_with_base, client, gpt_model)

    # Test Case ìë™ì‹¤í–‰
    if st.button("â–¶ï¸ Test Case ì‹¤í–‰ (AIëŠ” ì‹¤ìˆ˜ë¥¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)"):
        print(test_case)
        run_test_case(test_case, client, gpt_model)

    # ğŸ” ëŒ€í™” ë¦¬ì…‹ ë²„íŠ¼ (system ë©”ì‹œì§€ ì œì™¸)
    if st.button("âš ï¸ ëŒ€í™” ë¦¬ì…‹"):
        reset_chat()

    with open(config['default_code_path'], 'r', encoding='utf-8') as f:
        default_code = f.read()


    # í…ìŠ¤íŠ¸ ì˜ì—­ì— ê¸°ë³¸ê°’ìœ¼ë¡œ ì½”ë“œ í‘œì‹œ
    input_code = st.text_area("gptê°€ ìƒì„±í•œ ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”", value="", height=100)

    with open(config['run_code_path'], 'r', encoding='utf-8') as f:
        run_code = f.read()

    code = default_code + '\n' + input_code + '\n' + run_code
    if st.button("ì½”ë“œ ì‹¤í–‰"):
        output = io.StringIO()
        try:
            with contextlib.redirect_stdout(output):
                exec(code, {})
            st.success("ì‹¤í–‰ ì„±ê³µ!")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.text("ì¶œë ¥ ê²°ê³¼:")

        with open(config['result_base_path'], 'r', encoding='utf-8') as f:
            result_base = f.read()
            
        st.code(result_base + output.getvalue())