{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdb2b6aa",
   "metadata": {},
   "source": [
    "# 패턴 가르치기 - 가로직선 틀린 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0faa705",
   "metadata": {},
   "source": [
    "# Setting\n",
    "- GPT 모델 설정 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c83cee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "key_file = open('key.txt', 'r')\n",
    "os.environ['OPENAI_API_KEY'] = key_file.readline()\n",
    "key_file.close()\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "model = \"o4-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464b9510",
   "metadata": {},
   "source": [
    "- 첫 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8ce45f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# messages = []\n",
    "# system_content = '''\n",
    "\n",
    "# '''\n",
    "# user_content = '''\n",
    "\n",
    "# '''\n",
    "# messages.append({\"role\": \"system\", \"content\": system_content})\n",
    "# messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=model,\n",
    "#     messages=messages)\n",
    "# messages.append(response.choices[0].message)\n",
    "\n",
    "# print('*'*20, 'answer', '*'*20)\n",
    "# print(response.choices[0].message.content)\n",
    "# print('*'*40)\n",
    "# print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2723392",
   "metadata": {},
   "source": [
    "- 이어서 질문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0a14bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# user_content = '''\n",
    "\n",
    "# '''\n",
    "# messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "# response = client.chat.completions.create(\n",
    "#     model=model,\n",
    "#     messages=messages)\n",
    "# messages.append(response.choices[0].message)\n",
    "\n",
    "# print('*'*20, 'answer', '*'*20)\n",
    "# print(response.choices[0].message.content)\n",
    "# print('*'*40)\n",
    "# print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93400cdd",
   "metadata": {},
   "source": [
    "# 가로 직선 패턴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4390f777",
   "metadata": {},
   "source": [
    "## 패턴 설명 없이 문제풀이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d773a07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=151, prompt_tokens=97, total_tokens=248, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "messages = []\n",
    "\n",
    "system_content = '''\n",
    "너는 가로 방향 직선 패턴에 대해서 모른다. 가로 방향 직선 패턴에 대한 설명이 주어지면 설명을 기반으로 배열에 가로 방향 직선 패턴이 존재하는지 확인하고 결과를 출력한다. \n",
    "(존재하는 경우: True, 없는 경우: False)\n",
    "\n",
    "패턴 설명이 없는 경우 ‘풀 수 없습니다.’ 문구를 출력한다.\n",
    "'''\n",
    "\n",
    "user_content = '''\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"system\", \"content\": system_content})\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57237647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "이해했습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=151, prompt_tokens=157, total_tokens=308, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "Test case\n",
    "각각의 문제에 대한 결과를 출력한다. (결과는 True 또는 False 또는 ‘풀 수 없습니다.’만 출력한다.) \n",
    "이해했으면 ‘이해했습니다.’ 문구 출력\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5266e7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=535, prompt_tokens=223, total_tokens=758, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=512, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 8.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#1. [[1, 1, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c648250e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=279, prompt_tokens=289, total_tokens=568, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=256, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 5.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#2. [[1, 1, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66e641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=279, prompt_tokens=382, total_tokens=661, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=256, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 2.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#3. [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8552ee92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=215, prompt_tokens=508, total_tokens=723, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=192, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 5.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#4. [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17d067a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=343, prompt_tokens=634, total_tokens=977, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=320, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 3.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#5. [[0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019c0b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=471, prompt_tokens=727, total_tokens=1198, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=448, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 5.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#6. [[0, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a802ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "풀 수 없습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=151, prompt_tokens=820, total_tokens=971, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=128, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#7. [[0, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c17d008",
   "metadata": {},
   "source": [
    "## 패턴 설명 - 틀린 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "436e9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "이해했습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=279, prompt_tokens=966, total_tokens=1245, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=256, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 31.2 ms\n",
      "Wall time: 6.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "가로 방향 직선 패턴: 배열에서 1의 값을 가지는 위치들을 오름차순 정렬했을 때 열 값은 모두 동일하고 행 값이 1씩 증가한다.\n",
    "\n",
    "[예시]\n",
    "[[1, 0, 0, 0],\n",
    "[1, 0, 0, 0],\n",
    "[1, 0, 0, 0],\n",
    "[1, 0, 0, 0]]\n",
    "\n",
    "패턴: 열 값은 0으로 고정, 행 값은 0부터 1씩 증가한다.\n",
    "\n",
    "이해했다면 ‘이해했습니다.’ 문구 출력\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a469231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "이해했습니다.\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=407, prompt_tokens=1023, total_tokens=1430, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=384, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 4.42 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "Test case\n",
    " 각각의 문제에 대한 결과를 출력한다. (결과는 True 또는 False 또는 ‘풀 수 없습니다.’만 출력한다.) 이해했으면 ‘이해했습니다.’ 문구 출력\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0aa9f8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=800, prompt_tokens=1089, total_tokens=1889, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=768, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1024))\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 9.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#1. [[1, 1, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d762f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "False\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=532, prompt_tokens=1164, total_tokens=1696, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=512, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1024))\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 5.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#2. [[1, 1, 1, 1], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb1cbbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "False\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=1492, prompt_tokens=1254, total_tokens=2746, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=1472, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1024))\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#3. [[0, 0, 0, 0, 0], [0, 0, 0, 0, 0], [1, 1, 1, 1, 1], [0, 0, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cddbb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "False\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=532, prompt_tokens=1377, total_tokens=1909, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=512, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1152))\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 6.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#4. [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 1, 1, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "084d3f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "False\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=532, prompt_tokens=1500, total_tokens=2032, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=512, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1024))\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 6.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#5. [[0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb199896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "True\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=724, prompt_tokens=1590, total_tokens=2314, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=704, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0))\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 8.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#6. [[0, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "263202a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** answer ********************\n",
      "True\n",
      "****************************************\n",
      "tokens: CompletionUsage(completion_tokens=340, prompt_tokens=1680, total_tokens=2020, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=320, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=1536))\n",
      "CPU times: total: 78.1 ms\n",
      "Wall time: 4.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_content = ''' \n",
    "#7. [[0, 0, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 1, 0, 0, 0], [0, 0, 0, 0, 0]]\n",
    "'''\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": user_content})\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=messages)\n",
    "messages.append(response.choices[0].message)\n",
    "\n",
    "print('*'*20, 'answer', '*'*20)\n",
    "print(response.choices[0].message.content)\n",
    "print('*'*40)\n",
    "print('tokens:', response.usage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
